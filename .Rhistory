Note that to make the multiplicative model additive we made log
transformation, so we will transform them back to obtained forecast.
Plot the forecast to see the pattern.
```{r}
plot(forecast(model_first, h=5), main="F_Turkey")
```
Similar procedures followed and predictions made for second hand sales level("S_Turkey") this time.
```{r, echo=FALSE, message=FALSE}
ts_S_Turkey <- ts(evds$S_Turkey,freq=12,start = 2013)
ts_S_Turkey_log <- ts(log(evds$S_Turkey),freq=12,start = 2013)
ts_S_Turkey_log_reg_diff=diff(ts_S_Turkey_log)
#tsdisplay(ts_S_Turkey_log_reg_diff, lag.max = 24)
ts_S_Turkey_log_reg_s_diff=diff(ts_S_Turkey_log_reg_diff,12)
#tsdisplay(ts_S_Turkey_log_reg_s_diff, lag.max = 24)
model_second <- Arima(ts_S_Turkey_log, order=c(2,1,2), seasonal=c(1,0,0))
model_second
resid <- model_second$residuals
#tsdisplay(resid)
#qqPlot(resid)
#plot(c(model_second$residuals), main="Scatter Plot of Residuals", xlab = "Time
#     Index", ylab = "Residuals")
forecast_sales=forecast(model_second , h=5)
forecast_sales
real_forecast_second=exp(forecast_sales$mean)
```
```{r}
real_forecast_second
plot(forecast(model_second, h=5), main="S_Turkey")
```
Similar procedures followed and predictions made for second hand sales level("F_Antalya") this time.
```{r, echo=FALSE, message=FALSE}
ts_F_Antalya <- ts(evds$F_Antalya,freq=12,start = 2013)
ts_F_Antalya_log <- ts(log(evds$F_Antalya),freq=12,start = 2013)
#ts_S_Turkey_log_reg_diff=diff(ts_S_Turkey_log)
#tsdisplay(ts_S_Turkey_log_reg_diff, lag.max = 24)
#ts_S_Turkey_log_reg_s_diff=diff(ts_S_Turkey_log_reg_diff,12)
#tsdisplay(ts_S_Turkey_log_reg_s_diff, lag.max = 24)
model_first_antalya <- Arima(ts_F_Antalya_log, order=c(0,1,1), seasonal=c(2,0,0))
model_first_antalya
#resid <- model_first_antalya$residuals
#tsdisplay(resid)
#qqPlot(resid)
#plot(c(model_second$residuals), main="Scatter Plot of Residuals", xlab = "Time
#     Index", ylab = "Residuals")
forecast_sales=forecast(model_first_antalya , h=5)
forecast_sales
real_forecast_f_antalya=exp(forecast_sales$mean)
```
```{r}
real_forecast_f_antalya
plot(forecast(model_first_antalya, h=5), main="F_Antalya")
```
## Time Series - Future Prediction (2020 Plots)
PS: Note that to make the multiplicative model additive we made log
transformation, so we will transform them back to obtained forecasts.
ts_F_Antalya[85:91]
ts_F_Antalya
real_forecast_f_antalya
antalya_2020 <- c(ts_F_Antalya[85:91], real_forecast_f_antalya)
antalya_2020
samplelist = list(a = data.frame(x=c(1:7), y=antalya_2020[1:7]),
b = data.frame(x=c(7:12), y=antalya_2020[7:12]))
ggplot(bind_rows(samplelist, .id="df"), aes(x, y, colour=df)) + geom_line()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(dplyr)
library(cluster)
library(factoextra)
library(sp)
library(openxlsx)
library(tseries)
library(forecast)
library(readxl)
library(data.table)
library(ggplot2)
library(car)
evds = read.csv("https://raw.githubusercontent.com/pjournal/boun01g-hisrustu/gh-pages/housing_data_EVDS.csv")
mapPositions = read.xlsx("https://raw.githubusercontent.com/pjournal/boun01g-hisrustu/gh-pages/tr.xlsx")
TUR <- readRDS("TUR_1_sp.rds")
TUR_fixed <- fortify(TUR)
evds[c(90:100),c(1:5)]
names_and_numbers <- tibble(id=rownames(TUR@data),
city=TUR@data$NAME_1) %>%
left_join(mapPositions, by ="city")
final_map <- left_join(TUR_fixed, names_and_numbers, by = "id")
antalya_2020 <- c(ts_F_Antalya[85:91], real_forecast_f_antalya)
plot_list = list(real_value = data.frame(x=c(1:7), y=antalya_2020[1:7]),
forecasted = data.frame(x=c(7:12), y=antalya_2020[7:12]))
ggplot(bind_rows(plot_list, .id="df"), aes(x, y, colour=df)) + geom_line()
ggplot(bind_rows(plot_list, .id="df"), aes(x, y, colour=types)) + geom_line()
ggplot(bind_rows(plot_list, .id="types"), aes(x, y, colour=types)) + geom_line()
ggplot(bind_rows(plot_list, .id="types"), aes(x, y, colour=types)) + geom_line() + ggtitle("Antalya 2020")
knitr::opts_chunk$set(echo = TRUE)
#setwd("C:/Users/zuhre.b/Downloads")
library(tidyverse)
library(lubridate)
library(dplyr)
library(cluster)
library(factoextra)
library(sp)
library(openxlsx)
library(mapproj)
library(gridExtra)
library(ggthemes)
evds = read.csv("https://raw.githubusercontent.com/pjournal/boun01g-hisrustu/gh-pages/housing_data_EVDS.csv")
mapPositions = read.xlsx("https://raw.githubusercontent.com/pjournal/boun01g-hisrustu/gh-pages/tr.xlsx")
TUR <- readRDS("TUR_1_sp.rds")
TUR_fixed <- fortify(TUR)
convertName<-function(x,y){
x <- gsub(".*- (.+) -.*", "\\1", x)
x <- gsub("\u008d", "i", x)
x <- gsub("€", "C", x)
x <- gsub("ž", "S", x)
x <- gsub("Ÿ", "s", x)
x <- gsub("\u0081", "u", x)
x <- gsub("˜", "I", x)
x <- gsub("§", "g", x)
x <- gsub("”", "o", x)
x <- paste(y, x, sep="_")
return(x)
}
datainfo = evds[c(92:1080),]
cityNames<-evds[c(95:258),2]
firstHandCityNames<-cityNames[c(1:82)]
secondHandCityNames<-cityNames[c(83:164)]
evds = evds[c(1:91),]
firstHandCityNames<-convertName(firstHandCityNames,"F")
secondHandCityNames<-convertName(secondHandCityNames,"S")
allNames= c("Tarih",firstHandCityNames,secondHandCityNames)
names(evds)<-allNames
allNames
allNames[1]
allNames[2]
allNames[3]
allNames[37]
allNames[46]
allNames[47]
allNames[49]
allNames[59]
allNames[55]
allNames[56]
allNames[42]
allNames[123]
allNames[124]
ege_bolge %>% group_by(Year,Season) %>% summarise(SumData=sum(F_Antalya, F_Balikesir, F_Izmir, F_Aydin, F_Mugla)) %>%
ggplot(data = ., aes(x = Year, y = SumData, fill = Season)) +
geom_bar(stat="identity", position = position_dodge(), colour = "black") +
theme_minimal() +
theme(legend.position="top")+
labs(title = "Ege_Bolge")
load("spam_data.RData")
load("spambase.data")
summary(esoph)
View(esoph)
df <- read.csv("spam.csv", header = TRUE)
View(df)
table(df$spam)
table(df$spam)[0]
table(df$spam)[1]
table(df$spam)[2]
length(df)
length(df$spam)
table(df$spam)[2]/4601
table(df$testid)[2]/4601
filter(df, testid = TRUE & spam = TRUE)
filter(df, testid == TRUE & spam == TRUE)
filter(df, df$testid == TRUE & df$spam == TRUE)
filter(df, df$testid == TRUE & df$spam == TRUE)[, 'spam']
filter(df, df$testid == TRUE & df$spam == TRUE)[, ("spam")]
filter(df, df$testid == TRUE & df$spam == TRUE)[, c("spam")]
filter(df, df$testid == TRUE & df$spam == TRUE)["spam"]
length(filter(df, df$testid == TRUE & df$spam == TRUE))
length(filter(df, df$testid == TRUE & df$spam == TRUE))/51
length(filter(df, df$testid == TRUE & df$spam == TRUE))/59
library(RXKCD)
getXKCD(which = "current", display = TRUE, html = FALSE, saveImg = FALSE)
install.packages("RXKCD")
library(RXKCD)
getXKCD(which = "current", display = TRUE, html = FALSE, saveImg = FALSE)
getXKCD(which = "current", display = TRUE, html = FALSE, saveImg = FALSE)
getXKCD(which = "current", display = TRUE, html = FALSE, saveImg = FALSE)
serious
getXKCD(display = TRUE, html = FALSE, saveImg = FALSE)
getXKCD(35, display = TRUE, html = FALSE, saveImg = FALSE)
getXKCD(3545, display = TRUE, html = FALSE, saveImg = FALSE)
getXKCD(1, display = TRUE, html = FALSE, saveImg = FALSE)
getXKCD(2, display = TRUE, html = FALSE, saveImg = FALSE)
getXKCD(23, display = TRUE, html = FALSE, saveImg = FALSE)
getXKCD(25, display = TRUE, html = FALSE, saveImg = FALSE)
getXKCD(55, display = TRUE, html = FALSE, saveImg = FALSE)
getXKCD(565, display = TRUE, html = FALSE, saveImg = FALSE)
searchXKCD("support")
searchXKCD("data")
getXKCD(1683, display = TRUE, html = FALSE, saveImg = FALSE)
searchXKCD("data science")
searchXKCD("data analytics")
searchXKCD("analytics")
searchXKCD("R")
searchXKCD("R Language")
searchXKCD("R Programming")
getXKCD(816, display = TRUE, html = FALSE, saveImg = FALSE)
getXKCD(816, display = TRUE, html = FALSE, saveImg = FALSE)
searchXKCD("Programming")
searchXKCD("R Language")
getXKCD(529, display = TRUE, html = FALSE, saveImg = FALSE)
searchXKCD("regression")
getXKCD(1725, display = TRUE, html = FALSE, saveImg = FALSE)
searchXKCD("qqplot2")
searchXKCD("plot")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(dplyr)
library(tidyverse)
library(ggplot2)
data <- read.csv("spam.csv", header = TRUE)
colnames(data)
View(data)
class(data$spam)
levels(data$spam)
print(paste0("Percentage: ", round((nrow(filter(data, spam == TRUE))/nrow(data)) * 100, 2), "%"))
ggplot(data, aes(x=spam))
ggplot(data, aes(x=spam, y=nrow))
ggplot(data, aes(x=spam, y=testid))
View(data)
ggplot(data, aes(x=crl.ave)) +
geom_bar(aes(y = (..count..)/sum(..count..)))
data$crl.ave
ggplot(data, aes(x=crl.ave)) +
geom_bar(aes(y = (..count..)/sum(..count..)))
ggplot(data, aes(x=spam)) +
geom_bar(aes(y = (..count..)/sum(..count..)))
colnames(data)
ggplot(data, aes(x=table)) +
geom_bar(aes(y = (..count..)/sum(..count..)))
ggplot(data, aes(x=make)) +
geom_bar(aes(y = (..count..)/sum(..count..)))
ggplot(data, aes(x=all)) +
geom_bar(aes(y = (..count..)/sum(..count..)))
ggplot(data, aes(x=cr.long)) +
geom_bar(aes(y = (..count..)/sum(..count..)))
ggplot(data, aes(x=crl.long)) +
geom_bar(aes(y = (..count..)/sum(..count..)))
ggplot(data, aes(x=crl.long)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + xlim(2000)
ggplot(data, aes(x=crl.long)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + xlim(2000, 0)
ggplot(data, aes(x=crl.long)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + xlim(2000, 1)
ggplot(data, aes(x=crl.long)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + xlim(2000, 0)
ggplot(data, aes(x=crl.long)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + xlim(1000, 1)
data$spam <- recode(data$spam,
FALSE = "Not Spam",
TRUE = "Spam")
levels(data$spam)
data$spam <- recode(data$spam,
FALSE = "Not Spam",
TRUE = "Spam")
data$spam <- recode(data$spam, FALSE = "Not Spam", TRUE = "Spam")
data$spam <- recode(data$spam, FALSE = "Not Spam", TRUE = "Spam")
data$spam <- recode(data$spam, FALSE == "Not Spam", TRUE == "Spam")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(dplyr)
library(tidyverse)
library(dplyr)
library(tidyverse)
library(ggplot2)
data <- read.csv("spam.csv", header = TRUE)
print(paste0("Percentage: ", round((nrow(filter(data, spam == TRUE))/nrow(data)) * 100, 2), "%"))
View(data)
glimpse(data)
class(data$project[0])
class(data$spam[0])
class(data$testid[0])
library(tidyverse)
library(dplyr)
library(ggplot2)
library(rpart)
library(rpart.plot)
install.packages("rpart.plot")
library(tidyverse)
library(dplyr)
library(ggplot2)
library(rpart)
library(rpart.plot)
train <- subset(data, testid == TRUE)
test <- subset(data, testid == TRUE)
train <- subset(data, testid == FALSE)
print(paste0("Train > Percentage: ", round((nrow(filter(train, spam == TRUE))/nrow(data)) * 100, 2), "%"))
print(paste0("Test  > Percentage: ", round((nrow(filter(test, spam == TRUE))/nrow(data)) * 100, 2), "%"))
View(test[,-2])
train <- subset(data[,-3], testid == FALSE)
test <- subset(data[,-3], testid == TRUE)
print(paste0("Train > Percentage: ", round((nrow(filter(train, spam == TRUE))/nrow(data)) * 100, 2), "%"))
print(paste0("Test  > Percentage: ", round((nrow(filter(test, spam == TRUE))/nrow(data)) * 100, 2), "%"))
View(train)
train <- subset(data, testid == FALSE)
test <- subset(data, testid == TRUE)
train <- train[,-3]
test <- test[,-3]
View(train)
train <- subset(data[, -2], testid == FALSE)
test <- subset(data[, -2], testid == TRUE)
train <- subset(data, testid == FALSE)
test <- subset(data, testid == TRUE)
train <- subset(data[, -2], testid == FALSE)
test <- subset(data[, -2], testid == TRUE)
train <- subset(data, testid == FALSE)
test <- subset(data, testid == TRUE)
train <- subset(data, testid == FALSE)
test <- subset(data, testid == TRUE)
train <- train[, -2]
test <- test[, -2]
View(train)
data$spam <- as.factor(data$spam)
View(data)
class(data$spam[0])
class(train$spam[0])
reg_tree <- rpart(spam~., data = train, control = rpart.control(minsplit = 30))
View(reg_tree)
fancyRpartPlot(reg_tree)
plot(reg_tree)
prp(reg_tree)
View(reg_tree)
df <- data.frame(imp = reg_tree$variable.importance)
df2 <- df %>%
tibble::rownames_to_column() %>%
dplyr::rename("variable" = rowname) %>%
dplyr::arrange(imp) %>%
dplyr::mutate(variable = forcats::fct_inorder(variable))
ggplot2::ggplot(df2) +
geom_col(aes(x = variable, y = imp),
col = "black", show.legend = F) +
coord_flip() +
scale_fill_grey() +
theme_bw()
gs <- list(minsplit = c(2, 5, 10, 20, 30),
maxdepth = c(1, 3, 5, 10, 20)) %>%
cross_d() # Convert to data frame grid
gs
gs <- list(minsplit = c(2, 5, 10, 20, 30),
maxdepth = c(1, 3, 5, 10, 20)) %>%
cross_df() # Convert to data frame grid
gs
gs <- list(minsplit = c(2, 5, 10, 20, 30),
maxdepth = c(1, 3, 5, 10, 20)) %>%
cross_df() # Convert to data frame grid
mod <- function(...) {
rpart(Species ~ ., data = train, control = rpart.control(...))
}
gs <- gs %>% mutate(fit = pmap(gs, mod))
mod <- function(...) {
rpart(spam ~ ., data = train, control = rpart.control(...))
}
gs <- gs %>% mutate(fit = pmap(gs, mod))
compute_accuracy <- function(fit, test_features, test_labels) {
predicted <- predict(fit, test, type = "class")
mean(predicted == spam)
}
compute_accuracy <- function(fit, test_features, test_labels) {
predicted <- predict(fit, test_features, type = "class")
mean(predicted == test_labels)
}
test_features <- test %>% select(-spam)
test_labels   <- test$spam
gs <- gs %>%
mutate(test_accuracy = map_dbl(fit, compute_accuracy,
test_features, test_labels))
View(test_features)
View(gs)
View(gs)
predict(fit, test_features, type = "class")
map_dbl(fit, compute_accuracy,
test_features, test_labels)
summary(reg_tree)
compute_accuracy(reg_tree, test_features, test_labels)
reg_tree2 <- rpart(spam~., data = train)
plot(reg_tree2)
pdp(reg_tree2)
class(test$spam[0])
gs <- list(minsplit = c(2, 5, 10, 20, 30),
maxdepth = c(1, 3, 5, 10, 20)) %>%
cross_df() # Convert to data frame grid
mod <- function(...) {
rpart(spam ~ ., data = train, control = rpart.control(...))
}
gs <- gs %>% mutate(fit = pmap(gs, mod))
compute_accuracy <- function(fit, test_features, test_labels) {
predicted <- predict(fit, test_features, type = "class")
mean(predicted == test_labels)
}
test_features <- test %>% select(-spam)
test_labels   <- test$spam
gs <- gs %>%
mutate(test_accuracy = map_dbl(fit, compute_accuracy,
test_features, test_labels))
data$spam <- as.factor(data$spam)
train <- subset(data, testid == FALSE)
test <- subset(data, testid == TRUE)
train <- train[, -2]
test <- test[, -2]
print(paste0("Train > Percentage: ", round((nrow(filter(train, spam == TRUE))/nrow(data)) * 100, 2), "%"))
print(paste0("Test  > Percentage: ", round((nrow(filter(test, spam == TRUE))/nrow(data)) * 100, 2), "%"))
class(test$spam[0])
gs <- list(minsplit = c(2, 5, 10, 20, 30),
maxdepth = c(1, 3, 5, 10, 20)) %>%
cross_df() # Convert to data frame grid
mod <- function(...) {
rpart(spam ~ ., data = train, control = rpart.control(...))
}
gs <- gs %>% mutate(fit = pmap(gs, mod))
compute_accuracy <- function(fit, test_features, test_labels) {
predicted <- predict(fit, test_features, type = "class")
mean(predicted == test_labels)
}
test_features <- test %>% select(-spam)
test_labels   <- test$spam
gs <- gs %>%
mutate(test_accuracy = map_dbl(fit, compute_accuracy,
test_features, test_labels))
gs
View(gs)
reg_tree <- rpart(spam~., data = train, control = rpart.control(minsplit = 30, maxdepth = 10))
pdp(reg_tree)
prp(reg_tree)
confusionMatrix(predict(reg_tree, test_features, type = "class"), test$spam, positive = 'spam')
library(caret)
install.packages("caret")
library(caret)
confusionMatrix(predict(reg_tree, test_features, type = "class"), test$spam, positive = 'spam')
install.packages("e1071")
confusionMatrix(predict(reg_tree, test_features, type = "class"), test$spam, positive = 'spam')
confusionMatrix(predict(reg_tree, test_features, type = "class"), test$spam, positive = 'TRUE')
library(tidyverse)
library(dplyr)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(caret)
data$spam <- as.factor(data$spam)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(caret)
data <- read.csv("spam.csv", header = TRUE)
data$spam <- as.factor(data$spam)
train <- subset(data, testid == FALSE)
test <- subset(data, testid == TRUE)
train <- train[, -2]
test <- test[, -2]
compute_accuracy <- function(fit, test_features, test_labels) {
predicted <- predict(fit, test_features, type = "class")
mean(predicted == test_labels)
}
test_features <- test %>% select(-spam)
test_labels   <- test$spam
reg_tree <- rpart(spam~., data = train, control = rpart.control(minsplit = 30))
compute_accuracy(reg_tree, test_features, test_labels)
reg_tree <- rpart(spam~., data = train)
compute_accuracy(reg_tree, test_features, test_labels)
View(reg_tree)
prp(reg_tree)
View(reg_tree)
reg_tree <- rpart(spam~., data = train, control = rpart.control(minsplit = 3))
prp(reg_tree)
compute_accuracy(reg_tree, test_features, test_labels)
reg_tree2 <- rpart(spam~., data = train, control = rpart.control(minsplit = 3))
compute_accuracy(reg_tree2, test_features, test_labels)
reg_tree2 <- rpart(spam~., data = train, control = rpart.control(minsplit = 3343))
compute_accuracy(reg_tree2, test_features, test_labels)
reg_tree2 <- rpart(spam~., data = train, control = rpart.control(minsplit = 1))
compute_accuracy(reg_tree2, test_features, test_labels)
prp(reg_tree)
reg_tree2 <- rpart(spam~., data = train, control = rpart.control(maxdepth = 1))
prp(reg_tree)
compute_accuracy(reg_tree2, test_features, test_labels)
prp(reg_tree2)
reg_tree2 <- rpart(spam~., data = train, control = rpart.control(minsplit = 3))
prp(reg_tree2)
reg_tree2 <- rpart(spam~., data = train, control = rpart.control(maxdepth = 3))
prp(reg_tree2)
compute_accuracy(reg_tree2, test_features, test_labels)
reg_tree2 <- rpart(spam~., data = train, control = rpart.control(maxdepth = 2))
compute_accuracy(reg_tree2, test_features, test_labels)
reg_tree2 <- rpart(spam~., data = train, control = rpart.control(maxdepth = 4))
compute_accuracy(reg_tree2, test_features, test_labels)
gs <- list(minsplit = c(2, 5, 10, 20, 30),
maxdepth = c(2, 5, 10, 20, 30)) %>%
cross_df() # Convert to data frame grid
mod <- function(...) {
rpart(spam ~ ., data = train, control = rpart.control(...))
}
gs <- gs %>% mutate(fit = pmap(gs, mod))
gs <- gs %>% mutate(fit = pmap(gs, mod))
gs <- gs %>%
mutate(test_accuracy = map_dbl(fit, compute_accuracy,
test_features, test_labels))
gs
table(gs)
tibble(gs)
data_frame(gs)
print.data.frame(gs)
View(gs)
print.data.frame(gs[, c("minsplit", "maxdepth", "test_accuracy")])
gs[, c("minsplit", "maxdepth", "test_accuracy")] %>% filter(variable=="minsplit")
View(data)
